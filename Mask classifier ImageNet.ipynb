{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "files = list(os.listdir('E:/Jupyter/Face mask detection/dataset/training/with_mask'))\n",
    "for i in files:\n",
    "    img = load_img('E:/Jupyter/Face mask detection/dataset/training/with_mask/' + i, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    data.append(img)\n",
    "    labels.append('with_mask')\n",
    "\n",
    "    \n",
    "files = list(os.listdir('E:/Jupyter/Face mask detection/dataset/training/without_mask'))\n",
    "for i in files:\n",
    "    img = load_img('E:/Jupyter/Face mask detection/dataset/training/without_mask/' + i, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    data.append(img)\n",
    "    labels.append('without_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data_test = []\\nlabels_test = []\\n\\n\\nfiles = list(os.listdir('E:/Jupyter/Face mask detection/dataset/test/with_mask'))\\nfor i in files:\\n    img = load_img('E:/Jupyter/Face mask detection/dataset/test/with_mask/' + i, target_size=(224, 224))\\n    img = img_to_array(img)\\n    img = preprocess_input(img)\\n    data_test.append(img)\\n    labels_test.append('with_mask')\\n\\n    \\nfiles = list(os.listdir('E:/Jupyter/Face mask detection/dataset/test/without_mask'))\\nfor i in files:\\n    img = load_img('E:/Jupyter/Face mask detection/dataset/test/without_mask/' + i, target_size=(224, 224))\\n    img = img_to_array(img)\\n    img = preprocess_input(img)\\n    data_test.append(img)\\n    labels_test.append('without_mask')\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data_test = []\n",
    "labels_test = []\n",
    "\n",
    "\n",
    "files = list(os.listdir('E:/Jupyter/Face mask detection/dataset/test/with_mask'))\n",
    "for i in files:\n",
    "    img = load_img('E:/Jupyter/Face mask detection/dataset/test/with_mask/' + i, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    data_test.append(img)\n",
    "    labels_test.append('with_mask')\n",
    "\n",
    "    \n",
    "files = list(os.listdir('E:/Jupyter/Face mask detection/dataset/test/without_mask'))\n",
    "for i in files:\n",
    "    img = load_img('E:/Jupyter/Face mask detection/dataset/test/without_mask/' + i, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    data_test.append(img)\n",
    "    labels_test.append('without_mask')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data_test = np.array(data_test, dtype='float32')\\nlabels = np.array(labels)\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data_test = np.array(data_test, dtype='float32')\n",
    "labels = np.array(labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103, 224, 224, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(AveragePooling2D(pool_size=(7,7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.functional.Functional at 0x1ef42802c88>,\n",
       " <tensorflow.python.keras.layers.pooling.AveragePooling2D at 0x1ef4254b588>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x1ef4294c808>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1ef4291d188>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1ef4292b248>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1ef42938d48>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 1, 1, 1280)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,422,210\n",
      "Trainable params: 164,226\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "#labels_test = lb.fit_transform(labels_test)\n",
    "#labels_test = to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(rotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "steps_per_epoch_training = len(data)//batch_size\n",
    "#validation_step = len(data_test)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.005)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103, 224, 224, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.9):\n",
    "            print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.2658 - accuracy: 0.8777\n",
      "Epoch 2/30\n",
      "34/34 [==============================] - 39s 1s/step - loss: 0.2597 - accuracy: 0.8777\n",
      "Epoch 3/30\n",
      "34/34 [==============================] - 39s 1s/step - loss: 0.2853 - accuracy: 0.8665\n",
      "Epoch 4/30\n",
      "34/34 [==============================] - 39s 1s/step - loss: 0.2635 - accuracy: 0.8778\n",
      "Epoch 5/30\n",
      "34/34 [==============================] - 39s 1s/step - loss: 0.2462 - accuracy: 0.8880\n",
      "Epoch 6/30\n",
      "34/34 [==============================] - 39s 1s/step - loss: 0.2504 - accuracy: 0.8786\n",
      "Epoch 7/30\n",
      "34/34 [==============================] - 39s 1s/step - loss: 0.2722 - accuracy: 0.8824\n",
      "Epoch 8/30\n",
      "34/34 [==============================] - 38s 1s/step - loss: 0.2504 - accuracy: 0.8908\n",
      "Epoch 9/30\n",
      "26/34 [=====================>........] - ETA: 7s - loss: 0.2306 - accuracy: 0.8945"
     ]
    }
   ],
   "source": [
    "H = model.fit(\n",
    "        data_gen.flow(data, labels, batch_size=batch_size),\n",
    "        steps_per_epoch=steps_per_epoch_training,\n",
    "        epochs=30,  callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Mobilenet_mask_classifier_all_30_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model_json = model.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
